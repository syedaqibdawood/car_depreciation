{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e485e28e-f5c2-4701-9c5b-b287d03c4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b447e79-b97e-47a1-9023-65055e9692f7",
   "metadata": {},
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6807b518-c35d-4ea5-8e23-98bcd4c13b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"vehicles.csv\")  # Loading full dataset\n",
    "# df = df.sample(frac=0.5, random_state=42).reset_index(drop=True)  # Using 50% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2087ed32-77b5-4abb-8933-c580a43720da",
   "metadata": {},
   "outputs": [],
   "source": [
    " cols_to_drop = [\n",
    "                \"county\", \"size\", \"state\", \"region\", \"posting_date\", \n",
    "                \"paint_color\", \"drive\",\n",
    "            ]\n",
    "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "df.dropna(subset=[\"year\", \"odometer\", \"fuel\", \"model\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f02a25-99e6-4fe3-ad7e-364307181f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = 2025\n",
    "df[\"car_age\"] = current_year - df[\"year\"]\n",
    "df.drop(columns=[\"year\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49368b24-7ee6-4275-9341-44adffa35066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_base_model(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans a raw vehicle model name and returns the base model only.\n",
    "    No encoding is done here — just cleaning for consistency before encoding.\n",
    "    \"\"\"\n",
    "    if pd.isnull(name) or name.strip() == \"\":\n",
    "        return \"unknown\"\n",
    "\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'[^a-z0-9 ]', '', name)  # removing special characters\n",
    "    name = re.sub(\n",
    "        r'\\b(crew|cab|pickup|sedan|coupe|van|wagon|truck|convertible|utility|hatchback|2d|4d|4x4|fx4|awd|fwd|rwd|sr|ex|lx|le|lt|xlt|sel|slt|premium|limited|base|plus|l|gls|xle|se|xl|sport|touring|super|luxury|classic|series|class)\\b',\n",
    "        '', name\n",
    "    )\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    \n",
    "    # returning just the first word (base model)\n",
    "    return name.split()[0] if name else \"unknown\"\n",
    "df[\"model\"] = df[\"model\"].apply(extract_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d77ce04-2375-4072-91ec-ec661247ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Converting 'cylinders' to numeric if it's a string like \"4 cylinders\"\n",
    "if df['cylinders'].dtype == 'object':\n",
    "    df['cylinders'] = df['cylinders'].str.extract('(\\d+)')\n",
    "    df['cylinders'] = pd.to_numeric(df['cylinders'], errors='coerce')\n",
    "\n",
    "# Step 2: Dropping rows with missing values in relevant numeric columns\n",
    "df.dropna(subset=['price', 'odometer', 'car_age'], inplace=True)\n",
    "\n",
    "# Step 3: Defining numeric columns for outlier removal\n",
    "num_cols = ['price', 'odometer', 'car_age']\n",
    "\n",
    "# Step 4: IQR-based outlier removal function\n",
    "def remove_outliers_iqr(df, cols):\n",
    "    for col in cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Step 5: Applying outlier removal\n",
    "df = remove_outliers_iqr(df, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ef4639-288e-41f0-8e86-3e6a95d644ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"manufacturer\", \"fuel\", \"title_status\", \"model\", \"condition\", \"cylinders\", \"type\", \"transmission\"]\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d174c81-53ea-44fa-8e3d-c5326e133288",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"price\"\n",
    "df['price'] = np.log1p(df['price'])\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73020753-ced4-4f28-8fb9-0f2a78af7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c8725a-048c-4922-8083-96c6b3c65f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_transformer_object():\n",
    "        try:\n",
    "            numerical_features = [\"odometer\", \"car_age\"]\n",
    "            all_categorical_features = [\n",
    "                \"manufacturer\", \"fuel\", \"title_status\", \"model\", \"type\", 'cylinders', 'condition'\n",
    "            ]\n",
    "            mode_fill_columns = [\"transmission\"]\n",
    "\n",
    "            num_pipeline = Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\", StandardScaler())\n",
    "            ])\n",
    "\n",
    "            cat_pipeline_unknown = Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
    "                (\"encoder\", OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "                (\"scaler\", StandardScaler(with_mean=False))\n",
    "            ])\n",
    "\n",
    "            cat_pipeline_mode = Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"encoder\", OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "                (\"scaler\", StandardScaler(with_mean=False))\n",
    "            ])\n",
    "\n",
    "            general_cats = [col for col in all_categorical_features if col not in mode_fill_columns]\n",
    "\n",
    "            preprocessor = ColumnTransformer([\n",
    "                (\"num_pipeline\", num_pipeline, numerical_features),\n",
    "                (\"cat_pipeline_unknown\", cat_pipeline_unknown, general_cats),\n",
    "                (\"cat_pipeline_mode\", cat_pipeline_mode, mode_fill_columns)\n",
    "            ])\n",
    "\n",
    "            return preprocessor\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Transformer pipeline setup failed: {e}\")\n",
    "preprocessor = get_data_transformer_object()\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e0d456e-0462-4e24-b414-f8f2a49a5a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.1-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.15.2)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (3.10.1)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (6.0.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from plotly->catboost) (1.35.0)\n",
      "Downloading xgboost-3.0.1-py3-none-manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catboost-1.2.8-cp310-cp310-manylinux2014_x86_64.whl (99.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m175.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, xgboost, catboost\n",
      "Successfully installed catboost-1.2.8 graphviz-0.20.3 xgboost-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost catboost scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4932e160-465a-4456-8d4c-2fc64cf9b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "755cdc49-a018-4984-b177-3a3919cbdf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Starting model training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⏳ Progress:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training: Ridge Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⏳ Progress:  17%|█▋        | 1/6 [00:17<01:29, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished: Ridge Regression in 17.91 seconds\n",
      "\n",
      "🚀 Training: Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⏳ Progress:  33%|███▎      | 2/6 [02:16<05:08, 77.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished: Decision Tree in 118.61 seconds\n",
      "\n",
      "🚀 Training: AdaBoost Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⏳ Progress:  50%|█████     | 3/6 [11:32<14:47, 295.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished: AdaBoost Regressor in 555.72 seconds\n",
      "\n",
      "🚀 Training: Gradient Boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⏳ Progress:  67%|██████▋   | 4/6 [1:06:54<49:41, 1490.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished: Gradient Boosting in 3322.37 seconds\n",
      "\n",
      "🚀 Training: XGBRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⏳ Progress:  83%|████████▎ | 5/6 [1:07:27<16:05, 965.07s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished: XGBRegressor in 33.28 seconds\n",
      "\n",
      "🚀 Training: CatBoost Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⏳ Progress: 100%|██████████| 6/6 [1:14:47<00:00, 747.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished: CatBoost Regressor in 439.93 seconds\n",
      "\n",
      "✅ Best Model: Decision Tree\n",
      "📊 Evaluation Metrics:\n",
      "R2: 0.7124\n",
      "MAE: 2766.8074\n",
      "MSE: 49856813.9584\n",
      "RMSE: 7060.9358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Models listed from light to heavy\n",
    "models = {\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(verbosity=0),\n",
    "    \"CatBoost Regressor\": CatBoostRegressor(verbose=0),\n",
    "}\n",
    "\n",
    "# Evaluation function that reverses log1p transformation\n",
    "def evaluate_models(X_train, y_train, X_test, y_test, models):\n",
    "    report = {}\n",
    "    best_model = None\n",
    "    best_score = -np.inf\n",
    "\n",
    "    print(\"🔁 Starting model training...\\n\")\n",
    "    \n",
    "    for name in tqdm(models, desc=\"⏳ Progress\"):\n",
    "        model = models[name]\n",
    "        print(f\"\\n🚀 Training: {name}\")\n",
    "        start = time.time()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_log = model.predict(X_test)\n",
    "\n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "        print(f\"✅ Finished: {name} in {duration:.2f} seconds\")\n",
    "\n",
    "        # Unding the log1p transformation for evaluation\n",
    "        y_pred_actual = np.expm1(y_pred_log)\n",
    "        y_test_actual = np.expm1(y_test)\n",
    "\n",
    "        r2 = r2_score(y_test_actual, y_pred_actual)\n",
    "        report[name] = {\n",
    "            \"model\": model,\n",
    "            \"R2\": r2,\n",
    "            \"MAE\": mean_absolute_error(y_test_actual, y_pred_actual),\n",
    "            \"MSE\": mean_squared_error(y_test_actual, y_pred_actual),\n",
    "            \"RMSE\": np.sqrt(mean_squared_error(y_test_actual, y_pred_actual))\n",
    "        }\n",
    "\n",
    "        if r2 > best_score:\n",
    "            best_score = r2\n",
    "            best_model = model\n",
    "            best_model_name = name\n",
    "\n",
    "    return best_model, best_model_name, report\n",
    "\n",
    "# Calling the function\n",
    "best_model, best_model_name, model_report = evaluate_models(X_train, y_train, X_test, y_test, models)\n",
    "\n",
    "# Displaying results\n",
    "print(f\"\\n✅ Best Model: {best_model_name}\")\n",
    "print(\"📊 Evaluation Metrics:\")\n",
    "for metric, value in model_report[best_model_name].items():\n",
    "    if metric != \"model\":\n",
    "        print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44146a16-8c1c-4c21-b8a6-faa88b2bc819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model exported. Look in sidebar to download.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import shutil\n",
    "\n",
    "# Save and move the model\n",
    "joblib.dump(best_model, \"model.pkl\")\n",
    "shutil.move(\"model.pkl\", \"/home/ec2-user/SageMaker/model.pkl\")\n",
    "print(\"✅ Model exported. Look in sidebar to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7eca6-c740-4130-9bf4-f9179d2a4cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

""" model trainer
import os
import sys
from dataclasses import dataclass

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
from sklearn.metrics import r2_score

from src.exception import CustomException
from src.logger import logging
from src.utils import save_object, evaluate_models  # You must define evaluate_models in utils

@dataclass
class ModelTrainerConfig:
    trained_model_file_path = os.path.join("artifacts", "model.pkl")

class ModelTrainer:
    def __init__(self):
        self.model_trainer_config = ModelTrainerConfig()

    def initiate_model_trainer(self, train_array, test_array):
        try:
            logging.info("Converting sparse matrices to CSR format...")
            train_array = train_array.tocsr()
            test_array = test_array.tocsr()

            logging.info("Splitting features and target from arrays...")
            X_train = train_array[:, :-1]
            y_train = train_array[:, -1].toarray().ravel()

            X_test = test_array[:, :-1]
            y_test = test_array[:, -1].toarray().ravel()

            models = {
                "Random Forest": RandomForestRegressor(),
                "Decision Tree": DecisionTreeRegressor(),
                "Gradient Boosting": GradientBoostingRegressor(),
                "Linear Regression": LinearRegression(),
                "XGBRegressor": XGBRegressor(),
                "CatBoost Regressor": CatBoostRegressor(verbose=False),
                "AdaBoost Regressor": AdaBoostRegressor(),
            }

            params={
                "Decision Tree": {
                    'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],
                    # 'splitter':['best','random'],
                    # 'max_features':['sqrt','log2'],
                },
                "Random Forest":{
                    # 'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],
                 
                    # 'max_features':['sqrt','log2',None],
                    'n_estimators': [8,16,32,64,128,256]
                },
                "Gradient Boosting":{
                    # 'loss':['squared_error', 'huber', 'absolute_error', 'quantile'],
                    'learning_rate':[.1,.01,.05,.001],
                    'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],
                    # 'criterion':['squared_error', 'friedman_mse'],
                    # 'max_features':['auto','sqrt','log2'],
                    'n_estimators': [8,16,32,64,128,256]
                },
                "Linear Regression":{},
                "XGBRegressor":{
                    'learning_rate':[.1,.01,.05,.001],
                    'n_estimators': [8,16,32,64,128,256]
                },
                "CatBoosting Regressor":{
                    'depth': [6,8,10],
                    'learning_rate': [0.01, 0.05, 0.1],
                    'iterations': [30, 50, 100]
                },
                "AdaBoost Regressor":{
                    'learning_rate':[.1,.01,0.5,.001],
                    # 'loss':['linear','square','exponential'],
                    'n_estimators': [8,16,32,64,128,256]
                }
                
            }

            logging.info("Training and evaluating models...")
            model_report = evaluate_models(X_train, y_train, X_test, y_test, models, params)

            best_model_score = max(model_report.values())
            best_model_name = list(model_report.keys())[list(model_report.values()).index(best_model_score)]
            best_model = models[best_model_name]

            if best_model_score < 0.6:
                raise CustomException("No good model found (r2 < 0.6)")

            logging.info(f"Best model found: {best_model_name} with score {best_model_score}")

            save_object(
                file_path=self.model_trainer_config.trained_model_file_path,
                obj=best_model
            )

            predictions = best_model.predict(X_test)
            r2 = r2_score(y_test, predictions)
            return r2

        except Exception as e:
            raise CustomException(e, sys)
"""





""" data transformation
import os
import sys
from dataclasses import dataclass

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from scipy import sparse

from src.exception import CustomException
from src.logger import logging
from src.utils import save_object


@dataclass
class DataTransformationConfig:
    preprocessor_obj_file_path = os.path.join('artifacts', 'preprocessor.pkl')


class DataTransformation:
    def __init__(self):
        self.data_transformation_config = DataTransformationConfig()

    def get_data_transformer_object(self):
        try:
            logging.info("Setting up preprocessing pipelines...")

            numerical_features = ["odometer", "car_age"]
            categorical_features = [
                "region", "manufacturer", "model", "condition", "cylinders",
                "fuel", "title_status", "transmission", "drive", "type", "paint_color", "state"
            ]

            num_pipeline = Pipeline([
                ("imputer", SimpleImputer(strategy="median")),
                ("scaler", StandardScaler())
            ])

            cat_pipeline = Pipeline([
                ("imputer", SimpleImputer(strategy="most_frequent")),
                ("encoder", OneHotEncoder(handle_unknown='ignore')),
                ("scaler", StandardScaler(with_mean=False))
            ])

            preprocessor = ColumnTransformer([
                ("num_pipeline", num_pipeline, numerical_features),
                ("cat_pipeline", cat_pipeline, categorical_features)
            ])

            return preprocessor

        except Exception as e:
            raise CustomException(e, sys)

    def initiate_data_transformation(self, train_path, test_path):
        try:
            logging.info("Reading training and testing datasets...")
            train_df = pd.read_csv(train_path)
            test_df = pd.read_csv(test_path)

            # Step 1: Dropping high-missing/unwanted columns
            cols_to_drop = ["county", "size", "posting_date"]
            train_df.drop(columns=cols_to_drop, inplace=True, errors='ignore')
            test_df.drop(columns=cols_to_drop, inplace=True, errors='ignore')

            # Step 2: Dropping rows with missing year or odometer
            train_df.dropna(subset=["year", "odometer"], inplace=True)
            test_df.dropna(subset=["year", "odometer"], inplace=True)

            # Step 3: Feature engineering - Creating car_age
            current_year = 2025
            train_df["car_age"] = current_year - train_df["year"]
            test_df["car_age"] = current_year - test_df["year"]
            train_df.drop(columns=["year"], inplace=True)
            test_df.drop(columns=["year"], inplace=True)

            # Step 4: Separating features and target
            target_column = "price"
            X_train = train_df.drop(columns=[target_column])
            y_train = train_df[target_column]
            X_test = test_df.drop(columns=[target_column])
            y_test = test_df[target_column]

            # Step 5: Getting preprocessor and transforming data
            preprocessor = self.get_data_transformer_object()
            X_train_transformed = preprocessor.fit_transform(X_train)
            X_test_transformed = preprocessor.transform(X_test)

            # Step 6: Combining transformed features with target
            train_arr = sparse.hstack([X_train_transformed, y_train.values.reshape(-1, 1)])
            test_arr = sparse.hstack([X_test_transformed, y_test.values.reshape(-1, 1)])

            # Step 7: Saving preprocessor
            save_object(
                file_path=self.data_transformation_config.preprocessor_obj_file_path,
                obj=preprocessor
            )

            logging.info("Data transformation completed and preprocessor saved.")

            return train_arr, test_arr, self.data_transformation_config.preprocessor_obj_file_path

        except Exception as e:
            raise CustomException(e, sys)
            """
"""
pandas
numpy
seaborn
matplotlib
scikit-learn
catboost
xgboost
Flask
gunicorn

#-e .
"""
"""
models = {
    "Random Forest": RandomForestRegressor(),
    "Decision Tree": DecisionTreeRegressor(),
    "Gradient Boosting": GradientBoostingRegressor(),
    "Linear Regression": LinearRegression(),
    "XGBRegressor": XGBRegressor(verbosity=0),
    "CatBoost Regressor": CatBoostRegressor(verbose=0),
    "AdaBoost Regressor": AdaBoostRegressor(),
}
params = {
    "Decision Tree": {
        'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],
    },
    "Random Forest": {
        'n_estimators': [8, 16, 32, 64, 128, 256]
    },
    "Gradient Boosting": {
        'learning_rate': [.1, .01, .05, .001],
        'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9],
        'n_estimators': [8, 16, 32, 64, 128, 256]
    },
    "Linear Regression": {},
    "XGBRegressor": {
        'learning_rate': [.1, .01, .05, .001],
        'n_estimators': [8, 16, 32, 64, 128, 256]
    },
    "CatBoost Regressor": {
        'depth': [6, 8, 10],
        'learning_rate': [0.01, 0.05, 0.1],
        'iterations': [30, 50, 100]
    },
    "AdaBoost Regressor": {
        'learning_rate': [.1, .01, 0.5, .001],
        'n_estimators': [8, 16, 32, 64, 128, 256]
    }
}
def evaluate_models(X_train, y_train, X_test, y_test, models, params):
    report = {}
    best_model = None
    best_score = -np.inf

    for name, model in models.items():
        print(f"🔍 Tuning and training: {name}")
        param_grid = params.get(name, {})
        gs = GridSearchCV(model, param_grid, cv=3, n_jobs=1, scoring="r2", verbose=0)
        gs.fit(X_train, y_train)

        best_est = gs.best_estimator_
        y_pred = best_est.predict(X_test)

        r2 = r2_score(y_test, y_pred)
        report[name] = {
            "model": best_est,
            "R2": r2,
            "MAE": mean_absolute_error(y_test, y_pred),
            "MSE": mean_squared_error(y_test, y_pred),
            "RMSE": np.sqrt(mean_squared_error(y_test, y_pred))
        }

        if r2 > best_score:
            best_score = r2
            best_model = best_est
            best_model_name = name

    return best_model, best_model_name, report
best_model, best_model_name, model_report = evaluate_models(X_train, y_train, X_test, y_test, models, params)
print(f"\n✅ Best Model: {best_model_name}")
print("📊 Evaluation Metrics:")
for metric, value in model_report[best_model_name].items():
    if metric != "model":
        print(f"{metric}: {value:.4f}")
"""

"""
1
import os
import sys
from dataclasses import dataclass

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
2
df = pd.read_csv("vehicles.csv")  # Load full dataset
df.head()
3
 cols_to_drop = [
                "county", "size", "state", "region", "posting_date", 
                "paint_color", "drive"
            ]
df.drop(columns=cols_to_drop, inplace=True, errors='ignore')
df.dropna(subset=["year", "odometer", "fuel", "model"], inplace=True)
4
current_year = 2025
df["car_age"] = current_year - df["year"]
df.drop(columns=["year"], inplace=True)
5
import re
def extract_base_model(name: str) -> str:
    """
    Cleans a raw vehicle model name and returns the base model only.
    No encoding is done here — just cleaning for consistency before encoding.
    """
    if pd.isnull(name) or name.strip() == "":
        return "unknown"

    name = name.lower()
    name = re.sub(r'[^a-z0-9 ]', '', name)  # removing special characters
    name = re.sub(
        r'\b(crew|cab|pickup|sedan|coupe|van|wagon|truck|convertible|utility|hatchback|2d|4d|4x4|fx4|awd|fwd|rwd|sr|ex|lx|le|lt|xlt|sel|slt|premium|limited|base|plus|l|gls|xle|se|xl|sport|touring|super|luxury|classic|series|class)\b',
        '', name
    )
    name = re.sub(r'\s+', ' ', name).strip()
    
    # returning just the first word (base model)
    return name.split()[0] if name else "unknown"
df["model"] = df["model"].apply(extract_base_model)
6
target_column = "price"
X = df.drop(columns=[target_column])
y = df[target_column]
7
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
8
def get_data_transformer_object():
        try:
            numerical_features = ["odometer", "car_age"]
            all_categorical_features = [
                "manufacturer", "fuel", "title_status", "model",
                "condition", "cylinders", "type"
            ]
            mode_fill_columns = ["transmission"]

            num_pipeline = Pipeline([
                ("imputer", SimpleImputer(strategy="median")),
                ("scaler", StandardScaler())
            ])

            cat_pipeline_unknown = Pipeline([
                ("imputer", SimpleImputer(strategy="constant", fill_value="unknown")),
                ("encoder", OneHotEncoder(handle_unknown='ignore', sparse_output=False)),
                ("scaler", StandardScaler(with_mean=False))
            ])

            cat_pipeline_mode = Pipeline([
                ("imputer", SimpleImputer(strategy="most_frequent")),
                ("encoder", OneHotEncoder(handle_unknown='ignore', sparse_output=False)),
                ("scaler", StandardScaler(with_mean=False))
            ])

            general_cats = [col for col in all_categorical_features if col not in mode_fill_columns]

            preprocessor = ColumnTransformer([
                ("num_pipeline", num_pipeline, numerical_features),
                ("cat_pipeline_unknown", cat_pipeline_unknown, general_cats),
                ("cat_pipeline_mode", cat_pipeline_mode, mode_fill_columns)
            ])

            return preprocessor

        except Exception as e:
            raise Exception(f"Transformer pipeline setup failed: {e}")
preprocessor = get_data_transformer_object()
X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)
9
!pip install xgboost catboost scikit-learn
10
from sklearn.ensemble import (
    RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
)
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
import joblib
11
import time
from tqdm import tqdm  # For progress bar

# Light models listed first
models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(),
    "AdaBoost Regressor": AdaBoostRegressor(),
    "Gradient Boosting": GradientBoostingRegressor(),
    "XGBRegressor": XGBRegressor(verbosity=0),
    "CatBoost Regressor": CatBoostRegressor(verbose=0),
}

# Evaluation function with progress bar and timing
def evaluate_models(X_train, y_train, X_test, y_test, models):
    report = {}
    best_model = None
    best_score = -np.inf

    print("🔁 Starting model training...\n")
    
    for name in tqdm(models, desc="⏳ Progress"):
        model = models[name]
        print(f"\n🚀 Training: {name}")
        start = time.time()

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        end = time.time()
        duration = end - start
        print(f"✅ Finished: {name} in {duration:.2f} seconds")

        r2 = r2_score(y_test, y_pred)
        report[name] = {
            "model": model,
            "R2": r2,
            "MAE": mean_absolute_error(y_test, y_pred),
            "MSE": mean_squared_error(y_test, y_pred),
            "RMSE": np.sqrt(mean_squared_error(y_test, y_pred))
        }

        if r2 > best_score:
            best_score = r2
            best_model = model
            best_model_name = name

    return best_model, best_model_name, report

# Call the function
best_model, best_model_name, model_report = evaluate_models(X_train, y_train, X_test, y_test, models)

# Display results
print(f"\n✅ Best Model: {best_model_name}")
print("📊 Evaluation Metrics:")
for metric, value in model_report[best_model_name].items():
    if metric != "model":
        print(f"{metric}: {value:.4f}")
